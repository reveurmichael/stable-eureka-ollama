```python
def compute_reward(self, pos, action, state):
    distance_to_end = (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP - pos[0]
    speed_penalty = np.exp(-((state[3] + state[5]) / 2)**2)
    reward = 1 - speed_penalty
    individual_reward = {'distance_to_end': distance_to_end, 'speed_penalty': speed_penalty}
    return reward, individual_reward
```

Explanation: The reward function encourages the agent to move as fast as possible while penalizing its speed if it's not moving forward. This is achieved by subtracting the square of the average x and y velocities from 1, which creates a negative exponential relationship between speed and penalty. The distance_to_end component provides an additional incentive for the agent to reach the end of the terrain.