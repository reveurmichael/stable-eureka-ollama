def compute_reward(self, pos, action, state):
    hull_angle = state[0]
    vel_x = state[2]
    reached_end = pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP
    
    reward = 10.0 * (1.0 - np.exp(-0.01 * (np.abs(hull_angle)) ** 2)) + \
             5.0 * (1.0 - np.exp(-0.005 * vel_x ** 2))
    
    if reached_end:
        reward += 100.0
    
    individual_reward = {'hull_angle': hull_angle, 'velocity': vel_x}
    return reward, individual_reward