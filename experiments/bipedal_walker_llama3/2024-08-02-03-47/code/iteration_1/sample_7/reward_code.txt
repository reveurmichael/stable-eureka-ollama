def compute_reward(self, pos, action, state):
    hull_angle = state[0]
    velocity_x = state[2]
    velocity_y = state[3]
    
    if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP:
        reward = 1.0
        individual_reward = {"reach_end": 1.0}
    elif not self.game_over and velocity_x < 0:
        reward = 0.0
        individual_reward = {"fell_down": 0.0}
    else:
        reward = -0.01 * np.exp(-temperature) * (velocity_y ** 2 + hull_angle ** 2)
        individual_reward = {"stability": -0.01 * np.exp(-temperature) * (velocity_y ** 2 + hull_angle ** 2), "forward_movement": 0.01}
    
    return reward, individual_reward