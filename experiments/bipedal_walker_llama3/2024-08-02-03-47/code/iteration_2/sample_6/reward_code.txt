def compute_reward(self, pos, action, state):
    dist_to_end = (VIEWPORT_W / SCALE / 5) - pos[0]
    reward = np.exp(-dist_to_end / 10) * (1 if self.legs[1].ground_contact and self.legs[3].ground_contact else -0.01)
    individual_reward = {"progress": -dist_to_end, "balance": 0 if self.legs[1].ground_contact and self.legs[3].ground_contact else -1}
    return reward, individual_reward