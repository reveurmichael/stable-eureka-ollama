def compute_reward(self, pos, action, state):
    reaching_end = np.sign(pos[0] - TERRAIN_LENGTH + TERRAIN_GRASS) * (1.0 - abs((pos[0] - TERRAIN_LENGTH + TERRAIN_GRASS) / TERRAIN_STEP)) ** 2
    avoiding_falls = 1.0 - (state[6] + state[14]) / 2.0
    moving_forward = np.sign(action[0]) * abs(action[0])
    
    temperature = 5.0
    reward_exponential = np.exp((reaching_end + avoiding_falls + moving_forward) / temperature)
    total_reward = (reward_exponential - 1.0) / temperature
    
    individual_rewards = {"reaching_end": reaching_end, "avoiding_falls": avoiding_falls, "moving_forward": moving_forward}
    
    return total_reward, individual_rewards