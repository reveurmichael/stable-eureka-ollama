```python
def compute_reward(self, pos, action, state):
    reward = -1.0 * np.abs(action).sum()
    if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP:
        reward += 10.0
    if pos[0] < 0:
        reward -= 10.0
    individual_reward = {"action": -1.0 * np.abs(action).sum(), "reached_end": 10.0 if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP else 0.0, "fell_off": -10.0 if pos[0] < 0 else 0.0}
    return reward, individual_reward
```
This reward function encourages the agent to move forward by penalizing it for any movement and rewarding it for reaching the end of the terrain. It also discourages falling off the edge of the terrain by subtracting a penalty if the biped falls off.