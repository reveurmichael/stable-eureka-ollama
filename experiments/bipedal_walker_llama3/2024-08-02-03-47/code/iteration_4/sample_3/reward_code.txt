def compute_reward(self, pos, action, state):
    reward = -1.0 * np.abs(action).sum()
    if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP:
        reward += 10.0
    if pos[0] < 0:
        reward -= 10.0
    individual_reward = {"action": -1.0 * np.abs(action).sum(), "reached_end": 10.0 if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP else 0.0, "fell_off": -10.0 if pos[0] < 0 else 0.0}
    return reward, individual_reward