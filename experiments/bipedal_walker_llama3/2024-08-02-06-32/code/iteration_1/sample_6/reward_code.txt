def compute_reward(self, pos, action, state):
    hull_angle = state[0]
    x_vel = state[2]

    distance_to_goal = abs(pos[0] - TERRAIN_LENGTH)
    if self.game_over or pos[0] < 0:
        reward = -10.0
    else:
        reward = np.exp(-distance_to_goal / TERRAIN_LENGTH) * (1 + x_vel)

    individual_reward = {'hull_angle': hull_angle, 'x_velocity': x_vel}

    return reward, individual_reward