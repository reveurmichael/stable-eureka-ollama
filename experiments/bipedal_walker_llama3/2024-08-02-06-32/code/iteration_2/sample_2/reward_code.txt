def compute_reward(self, pos, action, state):
    if not self.game_over and not pos[0] < 0:
        # Forward movement reward
        forward_reward = min(np.exp((pos[0] - (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP) / TEMPERATURE_FORWARD), 1.0)
        
        # Avoid falling down and getting stuck rewards
        falling_down_reward = np.exp(-np.abs(pos[1]) / TEMPERATURE_FALLING_DOWN)
        getting_stuck_reward = min(np.exp((state[3] + state[15]) / TEMPERATURE_GETTING_STUCK), 1.0)
        
        reward = forward_reward * (1 - getting_stuck_reward) - falling_down_reward
    else:
        # Termination penalty if the biped has reached the end or fallen down
        reward = -np.exp((TERRAIN_LENGTH - pos[0]) / TEMPERATURE_TERMINATION)
    
    return reward, {'forward_movement': forward_reward, 'falling_down_avoidance': falling_down_reward, 'getting_stuck_avoidance': getting_stuck_reward}