def compute_reward(self, pos, action, state):
    hull_angle = state[0]
    linear_velocity_x = state[2]
    linear_velocity_y = state[3]

    distance_to_goal = abs(pos[0] - TERRAIN_LENGTH)
    reward = np.exp(-0.5 * (distance_to_goal / MAX_DISTANCE_TO_GOAL) ** 2)

    if not self.game_over:
        reward += np.exp(-1.5 * linear_velocity_x)  # encourage forward motion
    else:
        reward -= 10  # penalty for falling or reaching the end

    individual_reward = {'progress': -distance_to_goal, 'speed': -1 * linear_velocity_x}

    return reward, individual_reward