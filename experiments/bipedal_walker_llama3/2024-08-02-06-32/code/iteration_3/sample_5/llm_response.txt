```python
def compute_reward(self, pos, action, state):
    speed_x = state[2]
    speed_y = state[3]
    falling = not self.legs[1].ground_contact and not self.legs[3].ground_contact
    terminal_pos = TERRAIN_LENGTH - TERRAIN_GRASS
    reward = 0.0

    # Reward for reaching the end of the terrain
    if pos[0] > terminal_pos:
        reward += 10.0

    # Penalty for falling or getting stuck
    if falling or (not self.legs[1].ground_contact and not self.legs[3].ground_contact):
        reward -= 5.0

    # Reward for moving forward
    reward += 0.01 * speed_x

    # Normalize the reward
    reward = np.exp(reward - np.max([np.min([reward, 10.0]), -10.0]))

    return reward, {'end_reward': 10.0, 'fall_penalty': -5.0, 'move_reward': 0.01}