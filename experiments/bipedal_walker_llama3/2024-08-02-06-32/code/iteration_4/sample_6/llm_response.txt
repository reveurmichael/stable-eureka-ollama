```python
def compute_reward(self, pos, action, state):
    distance_to_end = abs(pos[0] - TERRAIN_LENGTH) / TERRAIN_STEP
    reward = -abs(action[0]) * 0.1 + 2.0 * (TERRAIN_GRASS - distance_to_end)
    
    individual_reward = {
        "distance_to_end": distance_to_end,
        "reward": reward,
        "velocity_x": state[3],
        "velocity_y": state[4]
    }
    
    return reward, individual_reward
```

This reward function rewards the agent for reaching the end of the terrain and penalizes it for moving in place. It also takes into account the velocity of the biped to encourage movement. The exact calculation is adjusted through a combination of exponential and linear transformations.