```python
def compute_reward(self, pos, action, state):
    # Calculate the distance to the end of the terrain
    distance_to_end = (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP - pos[0]
    
    # Calculate the reward for reaching the end of the terrain
    end_reach_reward = 10.0 * np.exp(-distance_to_end / 5.0)
    
    # Calculate the penalty for falling down or getting stuck
    if not self.game_over and (pos[1] < -MIN_HEIGHT or pos[0] > TERRAIN_LENGTH):
        fall_penalty = -20.0
    else:
        fall_penalty = 0.0
    
    # Calculate the reward for moving forward
    move_forward_reward = np.exp(pos[0] / 10.0)
    
    # Normalize and combine rewards
    total_reward = (end_reach_reward + move_forward_reward) * 0.5 + fall_penalty * 0.5
    
    return total_reward, {'end_reach': end_reach_reward, 'move_forward': move_forward_reward, 'fall_penalty': fall_penalty}
```