```python
def compute_reward(self, pos, action, state):
    reward = 0.0
    individual_reward = {"reach": 0.0, "speed": 0.0, "stability": 0.0, "obstacle_avoidance": 0.0}

    if not self.game_over and pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP:
        reward = 1.0
        individual_reward["reach"] = 1.0

    if action[2] > 0.5:  # or action[3] > 0.5:  # Add more conditions for knee and hip movements
        reward -= 0.1
        individual_reward["stability"] -= 0.1

    if any([l.fraction < 0.8 for l in self.lidar]):
        reward -= 0.2
        individual_reward["obstacle_avoidance"] -= 0.2

    if state[4] > 0.5 or state[14] > 0.5:
        reward -= 0.1
        individual_reward["stability"] -= 0.1

    if action[0] > 0.5:  # or action[3] > 0.5:  # Add more conditions for hip and knee movements
        reward += 0.05
        individual_reward["speed"] += 0.05

    return np.exp(reward), individual_reward
```