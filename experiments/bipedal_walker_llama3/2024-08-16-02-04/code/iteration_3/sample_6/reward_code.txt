def compute_reward(self, pos, action, state):
    distance_to_goal = VIEWPORT_W - abs(pos[0])
    falling_reward = np.exp(-1 * (pos[1] < 0))  # penalty for falling down
    moving_forward_reward = np.exp(action[0])  # reward for moving forward
    avoiding_stuck_reward = np.exp(1 / (state[-1] + state[-5]))  # penalty for getting stuck

    total_reward = distance_to_goal - falling_reward - moving_forward_reward - avoiding_stuck_reward
    individual_reward = {
        'distance_to_goal': distance_to_goal,
        'falling_reward': falling_reward,
        'moving_forward_reward': moving_forward_reward,
        'avoiding_stuck_reward': avoiding_stuck_reward
    }
    return total_reward, individual_reward