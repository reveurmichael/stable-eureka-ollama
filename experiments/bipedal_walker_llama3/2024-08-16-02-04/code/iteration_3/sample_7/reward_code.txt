def compute_reward(self, pos, action, state):
    distance_to_end = TERRAIN_LENGTH - pos[0]
    
    # Reward for moving forward
    forward_reward = np.exp(-distance_to_end / EXPONENTIAL_DISCOUNT)
    
    # Penalty for falling down
    fall_penalty = 1.0 if pos[0] < 0 else 0.0
    
    # Stiffness penalty: the more stuck the agent is, the lower the reward
    stiffness_penalty = 1.0 - np.mean([l.fraction for l in self.lidar])
    
    # Normalize and combine rewards
    reward = forward_reward * (1 - fall_penalty) * (1 - stiffness_penalty)
    individual_reward = {'forward': forward_reward, 'fall': fall_penalty, 'stiffness': stiffness_penalty}
    
    return reward, individual_reward