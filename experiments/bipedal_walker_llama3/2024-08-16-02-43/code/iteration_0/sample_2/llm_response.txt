```python
def compute_reward(self, pos, action, state):
    hull_angle = state[0]
    vel_x = state[2]
    distance_to_end = (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP - pos[0]

    reward = 1.0 + 0.1 * np.exp(temperature_param * (distance_to_end / ((TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP)))
    reward -= 0.01 * np.abs(hull_angle)
    reward -= 0.005 * np.abs(vel_x)

    individual_reward = {'progress': distance_to_end, 'orientation': hull_angle, 'velocity': vel_x}
    return reward, individual_reward
```

Explanation: The reward function encourages the biped to move forward towards the end of the terrain (progress), maintain a stable orientation and velocity. It uses exponential transformations with temperature parameters to scale the rewards.