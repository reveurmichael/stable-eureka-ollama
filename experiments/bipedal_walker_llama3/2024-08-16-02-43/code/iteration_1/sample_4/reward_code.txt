def compute_reward(self, pos, action, state):
    # Normalize position-based rewards using temperature parameter
    pos_reward = -np.exp(-((pos[0] - self.TERRAIN_LENGTH) / TERRAIN_GRASS)**2)
    
    # Reward for moving forward (faster the better)
    forward_reward = np.clip(action[0], -1, 1) * 10.0
    
    # Penalty for falling down
    fall_penalty = int(pos[0] < 0) * -100.0
    
    # Total reward is sum of individual components
    total_reward = pos_reward + forward_reward + fall_penalty
    
    # Dictionary of individual reward components
    return total_reward, {'position_reward': pos_reward, 'forward_reward': forward_reward, 'fall_penalty': fall_penalty}