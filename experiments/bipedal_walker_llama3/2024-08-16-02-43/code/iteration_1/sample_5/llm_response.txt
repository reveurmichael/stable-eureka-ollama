```python
def compute_reward(self, pos, action, state):
    hull_height = pos[1]
    terminal_state = pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP
    reward = 0.0
    
    if terminal_state:
        reward += 10.0  # bonus for reaching the end
    elif hull_height < 0.5:  # penalty for falling down
        reward -= 1.0
    
    if action[2] > 0 and action[3] > 0:  # walking forward with both legs
        reward += 0.1  # bonus for movement

    return reward, {'end_reached': terminal_state, 'fell_down': hull_height < 0.5, 'walking_forward': action[2] > 0 and action[3] > 0}
```

This reward function aims to encourage the agent to reach the end of the terrain while avoiding falling down. The reward is structured as follows:

- A bonus of 10.0 is given when the agent reaches the end of the terrain.
- A penalty of -1.0 is applied when the agent's hull height falls below 0.5, indicating that it has fallen down.
- A small bonus of 0.1 is given when the agent walks forward with both legs (i.e., both hip and knee joints are moving in the same direction). This encourages the agent to keep moving forward.