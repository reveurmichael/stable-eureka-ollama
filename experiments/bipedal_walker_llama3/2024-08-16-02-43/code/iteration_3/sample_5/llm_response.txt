```python
def compute_reward(self, pos, action, state):
    done = state[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP or pos[0] < 0
    reward = 1.0 if not done else -10.0
    
    individual_reward = {'distance': (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP - state[0], 'fell_down': -float(done)}
    
    return reward, individual_reward
```

Explanation: The goal is to make the biped navigate a 2D environment. The main reward function is based on whether the agent has reached the end of the terrain (positive reward) or fallen down (negative reward). To encourage the agent to move forward, the distance from the start to the current position is also considered in the individual reward dictionary.