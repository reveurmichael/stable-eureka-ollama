```python
def compute_reward(self, pos, action, state):
    distance_to_end = abs(pos[0] - (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP)
    falling_penalty = 1.0 if self.game_over else 0.0
    speed_reward = np.clip(action[0]**2 + action[1]**2, 0, 1)
    
    reward = -distance_to_end / (TERRAIN_LENGTH - TERRAIN_GRASS) * 10.0 - falling_penalty - 0.1
    
    individual_reward = {'distance_to_end': distance_to_end, 'speed_reward': speed_reward, 'falling_penalty': falling_penalty}
    
    return reward, individual_reward
```

Explanation: The reward function penalizes the agent for not reaching the end of the terrain (distance to end) and falling down. It also rewards the agent for moving forward quickly (speed). This encourages the agent to move as fast as possible while avoiding obstacles.