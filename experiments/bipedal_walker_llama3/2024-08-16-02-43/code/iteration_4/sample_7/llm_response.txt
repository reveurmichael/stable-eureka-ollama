```python
def compute_reward(self, pos, action, state):
    distance_to_end = TERRAIN_LENGTH - pos[0]
    movement_reward = np.exp((distance_to_end / TERRAIN_LENGTH) * TEMPERATURE)
    stability_reward = 1.0 - np.abs(state[2]) - np.abs(state[3])
    reward = movement_reward + stability_reward
    individual_rewards = {'movement': movement_reward, 'stability': stability_reward}
    return reward, individual_rewards
```

This reward function aims to balance the goal of moving forward (measured by distance_to_end) with the goal of avoiding falling down or getting stuck (measured by stability). The movement_reward is computed using an exponential transformation with a temperature parameter TEMPERATURE, which allows for more emphasis on early progress. The stability_reward is simply a measure of how close the biped is to being upright and stable.