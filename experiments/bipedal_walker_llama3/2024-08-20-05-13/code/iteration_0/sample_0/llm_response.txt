```python
def compute_reward(self, pos, action, state):
    hull_angle_diff = abs(pos[0] - self.prev_pos[0]) if self.prev_pos else 1.0
    prev_pos = pos.copy()

    # Reward for moving forward
    forward_reward = min(hull_angle_diff * 10, 5) if not self.game_over else 0

    # Punish falling down or getting stuck
    fall_punishment = -50 if (pos[1] < TERRAIN_HEIGHT - 2 and self.prev_pos[1] >= TERRAIN_HEIGHT - 2) or abs(pos[0] - self.prev_pos[0]) < 0.05 else 0

    # Reward for reaching the end
    end_reward = 100 if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP and not self.game_over else 0

    reward = forward_reward + fall_punishment + end_reward
    individual_reward = {'forward': forward_reward, 'fall': fall_punishment, 'end': end_reward}
    return reward, individual_reward
```

Explanation: The reward function encourages the agent to move forward by rewarding it for its progress towards the right side of the terrain. It also punishes the agent for falling down or getting stuck by subtracting a large value from its total reward. Finally, it rewards the agent with a large value if it reaches the end of the terrain without falling or getting stuck. The individual_reward dictionary provides a breakdown of these three components to help in debugging and visualizing the agent's behavior.