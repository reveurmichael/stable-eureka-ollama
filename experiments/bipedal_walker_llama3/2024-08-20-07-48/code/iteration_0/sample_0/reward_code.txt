def compute_reward(self, pos, action, state):
    hull_angle = state[0]
    x_velocity = state[2]
    y_velocity = state[3]
    distance_to_end = (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP - pos[0]

    # reward for moving forward
    move_reward = np.exp((x_velocity + 1.5) / 2.0)

    # penalty for falling down or getting stuck
    fall_penalty = np.exp(-np.abs(y_velocity)) if y_velocity < 0 else 0

    # penalty for not moving at all
    idle_penalty = np.exp(-np.clip(action[0], -1, 1) ** 2)

    # reward for reaching the end
    reach_reward = np.exp((distance_to_end / (TERRAIN_LENGTH - TERRAIN_GRASS)) * 5.0)

    total_reward = move_reward + fall_penalty - idle_penalty + reach_reward

    individual_rewards = {
        'move_reward': move_reward,
        'fall_penalty': fall_penalty,
        'idle_penalty': idle_penalty,
        'reach_reward': reach_reward
    }

    return total_reward, individual_rewards