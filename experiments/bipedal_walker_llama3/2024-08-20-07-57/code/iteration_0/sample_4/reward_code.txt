def compute_reward(self, pos, action, state):
    reward = -0.1 * (abs(action[0]) + abs(action[1]) + abs(action[2]) + abs(action[3])) + 0.1 * np.exp(-10 * ((pos[0] - TERRAIN_LENGTH) ** 2))
    individual_reward = {'action_penalty': -0.1 * (abs(action[0]) + abs(action[1]) + abs(action[2]) + abs(action[3])), 'distance_reward': 0.1 * np.exp(-10 * ((pos[0] - TERRAIN_LENGTH) ** 2))}
    return reward, individual_reward