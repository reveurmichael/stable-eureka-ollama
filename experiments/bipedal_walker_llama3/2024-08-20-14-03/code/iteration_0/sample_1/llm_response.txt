```python
def compute_reward(self, pos, action, state):
    reward = 0.0
    individual_reward = {"reached_end": 0.0, "avoided_falling": 0.0, "moved_forward": 0.0}

    if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP:
        reward += 10.0
        individual_reward["reached_end"] = 10.0

    if not self.game_over and pos[1] < 0:
        reward -= 5.0
        individual_reward["avoided_falling"] = -5.0

    if action.std() > 0.5 or abs(action.mean()) > 2.0:
        reward += 3.0
        individual_reward["moved_forward"] = 3.0

    reward *= np.exp(-1.0 * state[6] ** 2)
    return reward, individual_reward