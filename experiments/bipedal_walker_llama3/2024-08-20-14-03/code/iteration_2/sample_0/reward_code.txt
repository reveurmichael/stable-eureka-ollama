def compute_reward(self, pos, action, state):
    hull_angle = (state[0] + math.pi) % (2 * math.pi) - math.pi
    vel_x = state[3]
    dist_to_goal = (pos[0] - TERRAIN_LENGTH) / TERRAIN_STEP
    
    # Scale down distance_to_goal to give it a similar weight to others
    dist_to_goal_scaled = dist_to_goal / 10000.0
    
    reward = 10 * self.fitness_score + 5 * vel_x - 2 * dist_to_goal_scaled
    
    individual_reward = {'hull_alignment': 0.5 * np.exp(1) * (np.cos(hull_angle)),
                         'velocity': 5 * np.abs(vel_x),
                         'distance_to_goal': -2 * dist_to_goal_scaled}
    
    return reward, individual_reward