def compute_reward(self, pos, action, state):
    hull_angle = (state[0] + math.pi) % (2 * math.pi) - math.pi
    vel_x = state[3]
    dist_to_goal = (pos[0] - TERRAIN_LENGTH) / TERRAIN_STEP
    
    velocity_reward = 0.5 * np.exp(1) * (np.abs(vel_x) / 10.387818298648272)
    distance_reward = -0.2 * np.exp(0.5) * dist_to_goal / 223187.69593763346
    fitness_reward = (fitness_score / abs(fitness_score.max())) + 1
    
    reward = velocity_reward + distance_reward + fitness_reward
    
    individual_rewards = {
        'hull_alignment': 0.5 * np.exp(1) * (np.cos(hull_angle)),
        'velocity': velocity_reward,
        'distance_to_goal': distance_reward,
        'fitness_score': fitness_reward
    }
    
    return reward, individual_rewards