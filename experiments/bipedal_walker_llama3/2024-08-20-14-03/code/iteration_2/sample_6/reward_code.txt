def compute_reward(self, pos, action, state):
    hull_angle = (state[0] + math.pi) % (2 * math.pi) - math.pi
    vel_x = state[3]
    dist_to_goal = (pos[0] - TERRAIN_LENGTH) / TERRAIN_STEP
    
    # Rescale velocity to be in [-1, 1]
    vel_reward = 2.0 * np.tanh(vel_x)
    
    # Rescale distance to goal to be in [0, 1]
    dist_reward = (1.0 - np.exp(-dist_to_goal)) / (np.exp(-111175) + 1e-6)
    
    # Scale fitness score to be in [0, 1]
    fitness_reward = 2.0 * (fitness_score + 103.6408826379627) / (222005.83415849577 + 1e-6)
    
    reward = vel_reward + dist_reward + fitness_reward
    
    individual_reward = {'velocity': vel_reward,
                          'distance_to_goal': dist_reward,
                          'fitness_score': fitness_reward}
    
    return reward, individual_reward