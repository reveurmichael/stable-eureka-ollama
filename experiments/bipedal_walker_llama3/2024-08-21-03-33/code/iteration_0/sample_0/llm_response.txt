```python
def compute_reward(self, pos, action, state):
    reward = -1.0
    individual_reward = {'distance_reached': 0, 'stability': 0}

    if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP:
        reward += 10.0
        individual_reward['distance_reached'] = 10.0

    if not self.game_over and abs(vel.x) < 1e-2 and abs(vel.y) < 1e-2:
        reward -= 0.5
        individual_reward['stability'] = -0.5

    return reward, individual_reward
```
This code calculates a negative reward for every step the biped takes, except when it reaches the end of the terrain or achieves stability by not moving much. The 'distance_reached' and 'stability' rewards are calculated based on the position and velocity of the biped, with higher values for reaching the end and achieving stability, respectively.