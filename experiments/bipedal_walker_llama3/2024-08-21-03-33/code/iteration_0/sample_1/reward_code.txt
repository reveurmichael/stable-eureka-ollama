def compute_reward(self, pos, action, state):
    hull_angle = state[0]
    hull_velocity_x = state[2]
    is_leg_on_ground = (state[-1] > 0.5) or (state[-5] > 0.5)
    
    reward = -np.abs(hull_velocity_x) * 0.1
    if pos[0] < 0:
        reward -= 100.0
    elif is_leg_on_ground:
        reward -= 10.0
    
    individual_reward = {'hull_angle': np.exp((state[0] + math.pi) / (2 * math.pi)) - 0.5,
                          'velocity_x': -np.abs(hull_velocity_x),
                          'leg_on_ground': is_leg_on_ground}
    
    return reward, individual_reward