def compute_reward(self, pos, action, state):
    distance_to_goal = abs(pos[0] - TERRAIN_LENGTH)
    movement_reward = np.exp(-(distance_to_goal ** 2) / 1000) * (1 if pos[0] > TERRAIN_GRASS * TERRAIN_STEP else 0.5)
    
    penalty = -0.001 * (state[6] + state[13])  # Re-scaled and modified
    
    fitness_reward = np.exp(fitness_score)  # Maximize the fitness score
    
    reward = movement_reward + penalty + fitness_reward
    
    individual_reward = {"progress": movement_reward, "penalty": penalty, "fitness": fitness_reward}
    
    return reward, individual_reward