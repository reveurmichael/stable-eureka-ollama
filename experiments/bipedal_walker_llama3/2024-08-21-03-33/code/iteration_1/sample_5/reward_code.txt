def compute_reward(self, pos, action, state):
    distance_to_goal = abs(pos[0] - TERRAIN_LENGTH)
    moving_forward = not self.game_over and (pos[0] < 0 or pos[0] > TERRAIN_GRASS * TERRAIN_STEP)

    # Scale down the penalty component
    penalty = -0.001 * (state[6] + state[13])

    # Create a weighted combination of components
    reward = np.exp(-(distance_to_goal ** 2) / 1000) * 0.5 + moving_forward * 0.3 + penalty

    individual_reward = {"progress": np.exp(-(distance_to_goal ** 2) / 1000), 
                          "moving_forward": moving_forward, 
                          "penalty": penalty}

    return reward, individual_reward