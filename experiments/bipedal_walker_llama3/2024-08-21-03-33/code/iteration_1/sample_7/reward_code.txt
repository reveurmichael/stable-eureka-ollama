def compute_reward(self, pos, action, state):
    distance_to_goal = abs(pos[0] - TERRAIN_LENGTH)
    
    # Adjust the magnitude of moving_forward to make it more significant
    moving_forward_reward = 10.0 * (1 if pos[0] > TERRAIN_GRASS * TERRAIN_STEP else 0)
    
    # Scale down the penalty component to avoid overwhelming the reward signal
    penalty = -0.005 * (state[6] + state[13])
    
    # Maximize the fitness score by adding a positive reward term
    fitness_score_reward = 10.0 * np.exp(-np.abs(fitness_score))
    
    total_reward = moving_forward_reward + penalty + fitness_score_reward
    
    individual_rewards = {
        "progress": np.exp(-(distance_to_goal ** 2) / 1000),
        "moving_forward": moving_forward_reward,
        "penalty": penalty,
        "fitness_score": fitness_score_reward
    }
    
    return total_reward, individual_rewards