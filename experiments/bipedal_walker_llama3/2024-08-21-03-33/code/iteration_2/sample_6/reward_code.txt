def compute_reward(self, pos, action, state):
    distance_to_goal = abs(pos[0] - TERRAIN_LENGTH)
    moving_forward = not self.game_over and (pos[0] < 0 or pos[0] > TERRAIN_GRASS * TERRAIN_STEP)

    # Scale the fitness score to make it more relevant
    fitness_score_reward = np.exp(-(fitness_score ** 2) / 1000000)  # Adjust the exponent here

    # Reward progress towards the goal
    progress_reward = np.exp(-(distance_to_goal ** 2) / 10000)

    # Penalty for not moving forward (similar to the original penalty component)
    penalty = -0.01 * (state[6] + state[13])

    # Combine the rewards with weights
    reward = 0.8 * fitness_score_reward + 0.1 * progress_reward + 0.1 * penalty

    individual_reward = {"fitness_score": fitness_score_reward, "progress": progress_reward, "penalty": penalty}

    return reward, individual_reward