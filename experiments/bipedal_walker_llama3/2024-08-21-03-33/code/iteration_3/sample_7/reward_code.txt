def compute_reward(self, pos, action, state):
    distance_to_goal = abs(pos[0] - TERRAIN_LENGTH)
    moving_forward = not self.game_over and (pos[0] < 0 or pos[0] > TERRAIN_GRASS * TERRAIN_STEP)

    # Scale the penalty component
    penalty = -0.001 * (state[6] + state[13])

    # Flip the sign of fitness_score to maximize it during training
    fitness_reward = -(fitness_score)

    # Combine components with weights
    reward = 0.5 * np.exp(-(distance_to_goal ** 2) / 1000) * (1 if moving_forward else 0) + 0.3 * penalty + 0.2 * fitness_reward

    individual_rewards = {"progress": np.exp(-(distance_to_goal ** 2) / 1000), "moving_forward": 1 if moving_forward else 0, "penalty": -0.001 * (state[6] + state[13]), "fitness": fitness_reward}

    return reward, individual_rewards