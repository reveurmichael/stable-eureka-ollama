```python
def compute_reward(self, pos, action, state):
    distance_reward = (pos.x - TERRAIN_LENGTH) / 400.0 if pos.x < TERRAIN_LENGTH else 1.0
    distance_reward = np.exp(distance_reward)

    angle_penalty = -np.abs(state[0])
    angle_penalty = np.tanh(angle_penalty / 0.5)

    angular_velocity_penalty = -np.abs(state[1])
    angular_velocity_penalty = np.tanh(angular_velocity_penalty / 0.5)

    action_penalty = -np.sum(np.abs(action)) / len(action)
    action_penalty = np.tanh(action_penalty / 0.5)

    obstacle_penalty = -np.min([l.fraction for l in self.lidar])
    obstacle_penalty = np.exp(obstacle_penalty) if pos[0] > TERRAIN_GRASS else 1.0

    reward = (distance_reward
              + 0.2 * angle_penalty
              + 0.05 * angular_velocity_penalty
              + 0.15 * action_penalty
              + 0.6 * obstacle_penalty) if not self.game_over else -100

    individual_reward = {
        "distance_reward": distance_reward,
        "angle_penalty": angle_penalty,
        "angular_velocity_penalty": angular_velocity_penalty,
        "action_penalty": action_penalty,
        "obstacle_penalty": obstacle_penalty
    }

    return reward, individual_reward