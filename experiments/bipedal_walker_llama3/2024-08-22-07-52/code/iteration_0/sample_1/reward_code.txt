def compute_reward(self, pos, action, state):
    distance_reward = np.exp(pos.x / 400.0) - 1
    angle_penalty = -(state[0] ** 2)
    angular_velocity_penalty = -(state[1] ** 2)
    action_penalty = -(np.sum(np.abs(action)) / len(action))
    obstacle_penalty = -np.min([l.fraction for l in self.lidar])
    
    reward = (distance_reward + 
              0.05 * angle_penalty + 
              0.05 * angular_velocity_penalty + 
              0.1 * action_penalty + 
              0.6 * obstacle_penalty)
    
    if pos[0] > (TERRAIN_LENGTH - TERRAIN_GRASS) * TERRAIN_STEP:
        reward -= 100
    
    individual_reward = {
        "distance_reward": distance_reward,
        "angle_penalty": angle_penalty,
        "angular_velocity_penalty": angular_velocity_penalty,
        "action_penalty": action_penalty,
        "obstacle_penalty": obstacle_penalty
    }
    
    return reward, individual_reward