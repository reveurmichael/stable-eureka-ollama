def compute_reward(self, pos, action, state):
    # Fitness score-based reward: incentivize high scores
    fitness_reward = np.exp(fitness_score) * 0.5
    
    # Obstacle penalty: penalize proximity to obstacles
    obstacle_penalty = -np.min([l.fraction for l in self.lidar]) * 1.2
    
    # Distance-based reward: incentivize movement to the right (scaled)
    distance_reward = pos.x / 200.0
    
    # Total reward: a weighted sum with adjusted weights
    reward = (fitness_reward + 0.3 * obstacle_penalty + 0.4 * distance_reward)
    
    individual_reward = {
        "fitness_reward": fitness_reward,
        "obstacle_penalty": obstacle_penalty,
        "distance_reward": distance_reward
    }
    
    return reward, individual_reward