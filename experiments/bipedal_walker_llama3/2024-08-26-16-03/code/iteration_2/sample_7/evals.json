{
    "distance_reward": [
        94.21489235284733,
        94.7254415270894,
        94.35286860611424,
        72.13674483425632,
        77.06455440981745,
        73.65998016849326,
        73.9084759414961,
        76.50175005637234,
        76.95812654678463,
        77.84727682653083
    ],
    "stability_reward": [
        -0.572782612645615,
        -0.6156724695056,
        -0.6108821793320272,
        -0.342165862666779,
        -0.3470156906039932,
        -0.34648729004571244,
        -0.4018462181806082,
        -0.35983433598672826,
        -0.38140702378622876,
        -0.3466014875583752
    ],
    "smoothness_reward": [
        -36.83669763635645,
        -54.05759362231784,
        -67.45922393007142,
        -76.76260799872742,
        -53.80281867950977,
        -61.722159223811445,
        -46.31927357784693,
        -41.141232491198934,
        -31.356441815953687,
        -23.25008372208898
    ],
    "obstacle_avoidance_reward": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
    ],
    "fitness_score": [
        -20.6335726169647,
        -30.288886816006293,
        -37.80616792169583,
        -43.025551383540176,
        -30.146520597875043,
        -34.58850842717285,
        -25.95003790660982,
        -23.050458889797234,
        -17.566557399928634,
        -13.025602000765524
    ],
    "reward": [
        21.62597051379271,
        20.886129867983982,
        20.12362374458462,
        14.144731273525394,
        16.52394533692859,
        15.276914175832644,
        16.100878136232495,
        17.01440060150344,
        17.614498474169523,
        18.247324645053595
    ],
    "episode_length": [
        1600.0,
        1600.0,
        1600.0,
        1600.0,
        1600.0,
        1600.0,
        1600.0,
        1600.0,
        1600.0,
        1600.0
    ]
}