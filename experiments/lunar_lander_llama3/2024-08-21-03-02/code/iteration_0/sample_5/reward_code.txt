def compute_reward(self, state, m_power, s_power, terminated):
    # Define the reward structure
    reward = 0.0
    if not terminated:
        # Reward for moving closer to the helipad (positive)
        reward += -np.abs(state[1])  # negative because we want to move up

        # Punish for falling or being too far from the helipad (negative)
        if abs(state[0]) >= 1.0:
            reward -= 10.0  # penalty for falling
        elif np.abs(state[1]) > 0.5:  # not close enough to helipad
            reward -= 2.0

        # Reward for using main engines (positive)
        if m_power > 0.0:
            reward += 1.0

        # Punish for using side engines too much (negative)
        if s_power > 0.5:  # too much side engine use
            reward -= 2.0

    else:
        # Game over, punish the agent
        reward = -10.0

    return reward, {"main_engine": m_power, "side_engine": s_power}