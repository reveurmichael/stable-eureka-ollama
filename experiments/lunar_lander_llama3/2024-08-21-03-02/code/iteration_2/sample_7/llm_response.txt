A challenging task!

After analyzing the code, I'll attempt to provide a reward function that reflects the desired behavior. Please note that this might not be perfect, as it's based on my understanding of the code and the environment.

Here's my proposed reward function:
```python
def compute_reward(state, m_power, s_power, terminated):
    # Reward structure: (0-1) * 100 = -100 to 0

    # Penalty for not reaching the helipad
    helipad_dist = abs(state[1]) / (VIEWPORT_H / SCALE / 2)
    penalty = max(helipad_dist - 0.5, 0)

    # Reward for orientation and side engines
    if m_power > 0:
        reward_m = 10 * m_power  # scale down the main engine power to a reasonable range (0-100)
    else:
        reward_m = 0

    if s_power > 0:
        reward_s = 5 * s_power  # scale down the side engines power to a reasonable range (0-50)
    else:
        reward_s = 0

    # Total reward is the sum of penalties and rewards
    total_reward = -penalty + reward_m + reward_s

    individual_reward = {'main_engine': reward_m, 'side_engines': reward_s}
    return total_reward, individual_reward
```
This reward function aims to:

1. Encourage the agent to reach the helipad by penalizing its distance from it.
2. Reward main engine power (m_power) when it's above a certain threshold, scaling down the reward to a reasonable range (0-100).
3. Reward side engines power (s_power) when it's above a certain threshold, scaling down the reward to a reasonable range (0-50).

The total reward is calculated by summing up the penalties and rewards.