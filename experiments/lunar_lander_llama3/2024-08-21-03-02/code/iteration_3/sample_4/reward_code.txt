def compute_reward(state, m_power, s_power, terminated):
    # Define constants for reward shaping
    REWARD_REACH_HELIPAD = 10.0
    REWARD_STABLE_TRAJECTORY = 5.0
    PUNISH_FALLOFF_EDGE = -5.0

    # Calculate the distance to the helipad
    helipad_distance = np.sqrt((state[0] - VIEWPORT_W / SCALE / 2) ** 2 + (state[1] - self.helipad_y - LEG_DOWN / SCALE) ** 2)

    # Reward reaching the helipad
    if helipad_distance < 0.5:
        reward = REWARD_REACH_HELIPAD

    # Punish falling off the edge of the screen
    elif abs(state[0]) >= 1.0:
        reward = PUNISH_FALLOFF_EDGE

    # Encourage a stable and controlled trajectory
    else:
        reward = REWARD_STABLE_TRAJECTORY - (m_power + s_power) ** 2  # penalize engine usage

    if terminated:
        reward -= 10.0  # punish episode termination

    return reward, individual_reward