def compute_reward(self, state, m_power, s_power, terminated):
    # Define constants for the reward shape
    REWARD_SHAPE = -0.1  # penalty for not being close to the center
    REWARD_HEIGHT = 10.0  # reward for being near the helipad
    REWARD_VELOCITY = -0.5  # penalty for high velocity
    REWARD_ANGLE = -0.01  # penalty for large angle deviations

    # Calculate the reward based on the state and actions
    x_distance = state[0]
    y_distance = state[1]
    vx = state[2]
    vy = state[3]
    angle = state[4]
    angular_velocity = state[5]

    if terminated:
        return -10.0, {}  # penalty for game over

    reward = REWARD_SHAPE * (x_distance**2 + y_distance**2)  # penalize distance from center
    reward -= REWARD_HEIGHT * np.exp(-((self.helipad_y - state[1]) / (VIEWPORT_H / SCALE))**2)  # reward for being near the helipad
    reward -= REWARD_VELOCITY * (vx**2 + vy**2)  # penalize high velocity
    reward -= REWARD_ANGLE * np.abs(angle)  # penalize large angle deviations

    return reward, {}