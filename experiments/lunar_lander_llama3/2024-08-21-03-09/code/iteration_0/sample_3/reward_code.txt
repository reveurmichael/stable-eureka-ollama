def compute_reward(self, state, m_power, s_power, terminated):
    # Define the reward components
    position_reward = -abs(state[0])  # penalize deviations from the center
    velocity_reward = -state[2]**2 - state[3]**2  # penalize high velocities
    angle_reward = -state[4]**2  # penalize large angular deviations
    legs_contact_reward = 10.0 * (int(state[6]) + int(state[7]))  # reward for contact with both legs

    # Combine the rewards
    individual_reward = m_power * position_reward + s_power * velocity_reward - angle_reward + legs_contact_reward

    if terminated:
        individual_reward -= 100.0  # penalize termination

    return individual_reward, {'position': position_reward, 'velocity': velocity_reward, 'angle': angle_reward, 'legs_contact': legs_contact_reward}