def compute_reward(self, state, action, next_state, terminated):
    # Unpack state variables
    x, y, vx, vy, angle, angular_velocity, left_leg, right_leg = state
    
    # Distance-based reward: incentivize moving towards the landing pad
    distance_reward = -np.sqrt(x**2 + y**2)
    distance_reward = np.exp(distance_reward / 10.0) - 1
    
    # Height penalty: encourage stable flight heights
    height_penalty = -(y - self.helipad_y) ** 2
    height_penalty = np.tanh(height_penalty / 5.0)
    
    # Velocity penalty: discourage high velocities while allowing some movement
    velocity_penalty = -(np.abs(vx) + np.abs(vy)) ** 1.5
    velocity_penalty = np.exp(velocity_penalty / 10.0) - 1
    
    # Fuel efficiency reward: relax the fuel penalty to encourage exploration
    fuel_reward = 1 if action == 2 else 0.5
    
    # Landing reward: simplify and reduce bonus for successful landing
    landing_reward = 50 if left_leg and right_leg else 0
    
    # Total reward: a weighted sum of all components
    reward = (distance_reward * 0.3 + height_penalty * 0.2 + velocity_penalty * 0.3 + fuel_reward * 0.1 + landing_reward)
    
    # Apply a penalty if the episode is terminated (crash or out of bounds)
    if terminated and not (left_leg and right_leg):
        reward -= 50
    
    individual_reward = {
        "distance_reward": distance_reward,
        "height_penalty": height_penalty,
        "velocity_penalty": velocity_penalty,
        "fuel_reward": fuel_reward,
        "landing_reward": landing_reward,
    }
    
    return reward, individual_reward