def compute_reward(state, m_power, s_power, terminated):
    if terminated:
        # If the lander crashed or fell off the platform, penalize heavily
        return -10.0, {'crash': -10.0}

    # Calculate survival bonus (the longer the lander stays alive, the higher the reward)
    survival_bonus = 1.0 + (self.lander.alive_time / MAX_ALIVE_TIME)

    # Calculate distance from target (closer is better)
    dist_to_target = np.linalg.norm(state[:2] - TARGET_POSITION) / TARGET_RADIUS
    target_bonus = 1.0 - dist_to_target

    # Calculate angle and velocity control (smaller deviations are better)
    angle_deviation = np.abs(state[4] - TARGET_ANGLE)
    vel_deviation = np.linalg.norm([state[2], state[3]]) / MAX_VEL
    control_penalty = min(angle_deviation, 0.5) + min(vel_deviation, 0.5)

    # Calculate ground contact bonus (all legs grounded? award a bonus!)
    if all(self.lander.ground_contacts):
        ground_contact_bonus = 1.0
    else:
        ground_contact_bonus = 0.0

    # Combine the components and normalize the reward score
    reward = survival_bonus * target_bonus - control_penalty + ground_contact_bonus
    individual_reward = {'survival_bonus': survival_bonus, 'target_bonus': target_bonus,
                           'control_penalty': control_penalty, 'ground_contact_bonus': ground_contact_bonus}

    return reward, individual_reward